# https://mlcryptopres-jpehjeqv.manus.space/

import os
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data")

st.set_page_config(layout="wide")

if "page" not in st.session_state:
    st.session_state.page = 0

def next_page():
    st.session_state.page += 1

def prev_page():
    st.session_state.page -= 1


# ----------------------------
# Cargar y limpiar datos
# ----------------------------
@st.cache_data
def cargar_datos():
    csv_path = os.path.join(DATA_DIR, "crypto_historical_365days.csv")
    df = pd.read_csv(csv_path)

    df = df.dropna()

    # Ajusta aqu√≠ si luego cambias tu feature set
    df = df.drop(
        columns=[
            "coin_id",
            "symbol",
            "timestamp",
            "month",
            "cumulative_return",
        ],
        errors="ignore",
    )

    df["date"] = pd.to_datetime(df["date"])
    df = df.set_index("date").sort_index()

    # Target: retorno diario > 0 (1) / <= 0 (0)
    df["target"] = (df["daily_return"] > 0).astype(int)

    # Evitar duplicados (coin_name, date)
    df = (
        df.reset_index()
        .drop_duplicates(subset=["coin_name", "date"])
        .set_index("date")
        .sort_index()
    )

    return df


df = cargar_datos()


# ----------------------------
# Slide 0 - Intro + Contexto
# ----------------------------
if st.session_state.page == 0:
    st.title("üìä Predicci√≥n de movimientos diarios en criptomonedas con ML y Streamlit")
    st.write("Proyecto de Machine Learning aplicado a series temporales financieras.")
    st.image("https://cryptologos.cc/logos/bitcoin-btc-logo.png", width=90)

    st.markdown("---")

    colA, colB = st.columns([1.2, 1])

    with colA:
        st.subheader("üéØ Objetivo del proyecto")
        st.markdown(
            """
- **Clasificaci√≥n binaria:** ¬øel retorno diario ser√° **positivo** o **negativo**?
- No buscamos predecir el **precio exacto**, sino la **direcci√≥n** (sube/baja).
- Presentaci√≥n del flujo completo (datos ‚Üí EDA ‚Üí modelos ‚Üí resultados) en **Streamlit**.
            """
        )

    with colB:
        st.subheader("üß≠ Estructura")
        st.markdown(
            """
1. Problema y criterio (ML s√≠/no)
2. Datos y preparaci√≥n
3. EDA (qu√© aprendemos)
4. Modelos + overfitting
5. Resultados + impacto
6. Limitaciones + pr√≥ximos pasos
            """
        )

    st.button("Siguiente ‚ñ∂", on_click=next_page)


# ----------------------------
# Slide 1 - Datos + Problema + ¬øTiene sentido ML? + Limpieza
# (Aqu√≠ hacemos coexistir ‚ÄúSlide 2‚Äù y ‚ÄúSlide 3‚Äù conceptuales)
# ----------------------------
elif st.session_state.page == 1:
    st.header("üìÇ Datos, problema y preparaci√≥n")

    col1, col2 = st.columns([1.2, 1])

    with col1:
        st.subheader("‚ùì ¬øQu√© problema intentamos resolver?")
        st.markdown(
            """
- Los mercados cripto son **vol√°tiles** y dif√≠ciles de interpretar d√≠a a d√≠a.
- Queremos anticipar la **direcci√≥n del retorno diario**.
- El objetivo es **tendencia (sube/baja)**, no precios exactos.
            """
        )

        st.subheader("ü§î ¬øTiene sentido usar Machine Learning aqu√≠?")
        st.markdown(
            """
- Hay **datos hist√≥ricos** y un **target definido** (supervisado).
- Puede haber relaciones **no lineales** (retorno, volatilidad, etc.).
- Riesgo clave en series temporales: **overfitting** y **data leakage**.
            """
        )

    with col2:
        st.subheader("üìå Dataset y target")
        st.markdown(
            """
- Dataset con hist√≥ricos diarios de criptomonedas (Kaggle).
- Variables num√©ricas (retornos, volatilidad, m√©tricas temporales).
- **Target:** `daily_return > 0` ‚Üí 1, si no ‚Üí 0.
- Split temporal: **sin shuffle** (respetamos el orden).
            """
        )

    st.markdown("---")
    st.subheader("üßº Limpieza y feature engineering (vista r√°pida)")
    st.dataframe(df.head(), use_container_width=True)
    st.caption(f"Shape final: {df.shape}")

    st.markdown(
        """
**Qu√© se hace aqu√≠ (resumen):**
- Eliminaci√≥n de columnas no informativas  
- Tratamiento de nulos  
- Conversi√≥n de fechas e indexado temporal  
- Construcci√≥n expl√≠cita del target  
        """
    )

    colL, colR = st.columns(2)
    with colL:
        st.button("‚óÄ Anterior", on_click=prev_page)
    with colR:
        st.button("Siguiente ‚ñ∂", on_click=next_page)


# ----------------------------
# Slide 2 - EDA + Visualizaci√≥n
# ----------------------------
elif st.session_state.page == 2:
    st.header("üìà EDA y visualizaci√≥n ‚Äî Qu√© aprendemos antes de modelar")

    st.markdown(
        """
Antes de entrenar modelos, buscamos **estructura** en los datos:
- ¬øQu√© variables se relacionan entre s√≠?
- ¬øAparece alguna se√±al (aunque sea d√©bil) que justifique el ML?
- ¬øC√≥mo es la distribuci√≥n del target (sube/baja)?
        """
    )

    with st.expander("1) Matriz de correlaci√≥n"):
        fig, ax = plt.subplots(figsize=(10, 8))
        sns.heatmap(
            df.select_dtypes("number").corr(),
            cmap="coolwarm",
            center=0,
            annot=True,
            ax=ax,
        )
        st.pyplot(fig)

    with st.expander("2) Volatilidad vs Target (boxplot)"):
        fig, ax = plt.subplots(figsize=(6, 4))
        sns.boxplot(data=df, x="target", y="volatility_7d", ax=ax)
        ax.set_title("Volatilidad (7d) vs Target")
        st.pyplot(fig)

    with st.expander("3) Distribuci√≥n del Target y Daily Return"):
        fig, ax = plt.subplots()
        df["target"].value_counts(normalize=True).plot(kind="bar", ax=ax)
        ax.set_title("Distribuci√≥n del Target")
        st.pyplot(fig)

        fig, ax = plt.subplots()
        df[df["target"] == 1]["daily_return"].hist(alpha=0.6, label="Sube", ax=ax)
        df[df["target"] == 0]["daily_return"].hist(alpha=0.6, label="Baja", ax=ax)
        ax.legend()
        ax.set_title("Distribuci√≥n Daily Return por Target")
        st.pyplot(fig)

    with st.expander("4) Evoluci√≥n temporal del Target (media m√≥vil 30 d√≠as)"):
        fig, ax = plt.subplots()
        df.groupby(df.index)["target"].mean().rolling(30).mean().plot(ax=ax)
        ax.set_title("Media m√≥vil del Target (30 d√≠as)")
        st.pyplot(fig)

    with st.expander("5) Daily Return vs Volatility (scatter)"):
        fig, ax = plt.subplots(figsize=(6, 4))
        sns.scatterplot(
            data=df.sample(3000, random_state=42),
            x="volatility_7d",
            y="daily_return",
            hue="target",
            alpha=0.6,
            ax=ax,
        )
        ax.set_title("Daily Return vs Volatilidad (7d)")
        st.pyplot(fig)

    st.info(
        "Idea clave: aqu√≠ NO buscamos 'confirmar' que se puede predecir perfectamente, "
        "sino entender patrones y riesgos antes del modelado."
    )

    col1, col2 = st.columns(2)
    with col1:
        st.button("‚óÄ Anterior", on_click=prev_page)
    with col2:
        st.button("Siguiente ‚ñ∂", on_click=next_page)


# ----------------------------
# Slide 3 - Modelos + Overfitting + Resultados + Lectura
# ----------------------------
elif st.session_state.page == 3:
    import numpy as np
    import json
    from sklearn.metrics import ConfusionMatrixDisplay, classification_report, roc_auc_score
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split

    st.header("ü§ñ Modelos, overfitting y resultados")

    st.markdown(
        """
**Modelos probados (y por qu√©):**
- **Regresi√≥n Log√≠stica** ‚Üí baseline simple y estable  
- **Random Forest** ‚Üí capta relaciones no lineales  
- **XGBoost** ‚Üí modelo potente, pero propenso a sobreajustar si no se controla  
**M√©trica principal:** ROC AUC (m√°s informativa que accuracy cuando hay ruido/umbral).
        """
    )

    st.caption("Baseline entrenado en vivo (r√°pido) ¬∑ RF/XGB entrenados offline (solo resultados)")

    # Split temporal sin shuffle
    X = df.drop(columns=["target", "coin_name"], errors="ignore")
    y = df["target"]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

    # Resultados offline (RF + XGB)
    rf_cm = np.load(os.path.join(DATA_DIR, "rf_confusion.npy"))
    xgb_cm = np.load(os.path.join(DATA_DIR, "xgb_confusion.npy"))
    with open(os.path.join(DATA_DIR, "metrics.json")) as f:
        metrics = json.load(f)

    tabs = st.tabs(["Baseline (LogReg)", "Random Forest (offline)", "XGBoost (offline)"])

    with tabs[0]:
        st.subheader("Baseline: Logistic Regression")
        baseline = LogisticRegression(max_iter=1000)
        baseline.fit(X_train, y_train)

        y_pred = baseline.predict(X_test)
        y_prob = baseline.predict_proba(X_test)[:, 1]

        st.text(classification_report(y_test, y_pred))
        st.write("ROC AUC:", roc_auc_score(y_test, y_prob))

        fig, ax = plt.subplots()
        ConfusionMatrixDisplay.from_predictions(
            y_test, y_pred, display_labels=[0, 1], ax=ax, values_format="d"
        )
        st.pyplot(fig)

        st.markdown(
            """
**Lectura correcta:** baseline = referencia.  
Si un modelo complejo ‚Äúparece‚Äù muy bueno, pero no generaliza, suele ser **overfitting**.
            """
        )

    with tabs[1]:
        st.subheader("Random Forest Optimizado (Resultados finales)")
        st.write("Accuracy:", metrics["rf"]["accuracy"])
        st.write("ROC AUC:", metrics["rf"]["roc_auc"])
        st.write("F1-score:", metrics["rf"]["f1"])

        fig, ax = plt.subplots()
        ConfusionMatrixDisplay(rf_cm, display_labels=[0, 1]).plot(ax=ax, values_format="d")
        st.pyplot(fig)

        st.warning(
            "En series temporales financieras, es com√∫n que modelos potentes "
            "aprendan demasiado bien el training y pierdan generalizaci√≥n."
        )

    with tabs[2]:
        st.subheader("XGBoost (Optuna) (Resultados finales)")
        st.write("Accuracy:", metrics["xgb"]["accuracy"])
        st.write("ROC AUC:", metrics["xgb"]["roc_auc"])
        st.write("F1-score:", metrics["xgb"]["f1"])

        fig, ax = plt.subplots()
        ConfusionMatrixDisplay(xgb_cm, display_labels=[0, 1]).plot(ax=ax, values_format="d")
        st.pyplot(fig)

        st.warning(
            "Decisi√≥n t√©cnica clave: limitar complejidad / regularizar / validar con rolling, "
            "porque el riesgo real aqu√≠ es el **overfitting**."
        )

    st.markdown("---")
    st.subheader("üí° Impacto: ¬øpara qu√© sirve esto?")
    st.markdown(
        """
- Generar **se√±ales de tendencia diaria** como apoyo (no ‚Äúor√°culo‚Äù).
- Ayudar a priorizar an√°lisis: **filtro previo** para decisiones humanas.
- Base para sistemas m√°s complejos (validaci√≥n rolling, features extra, datos en tiempo real).
        """
    )

    col1, col2 = st.columns(2)
    with col1:
        st.button("‚óÄ Anterior", on_click=prev_page)
    with col2:
        st.button("Siguiente ‚ñ∂", on_click=next_page)


# ----------------------------
# Slide 4 - Limitaciones + Next steps + Cierre
# ----------------------------
elif st.session_state.page == 4:
    st.header("‚úÖ Conclusiones, limitaciones y pr√≥ximos pasos")

    colA, colB = st.columns(2)

    with colA:
        st.subheader("‚úÖ Conclusi√≥n")
        st.markdown(
            """
- Problema **realista**: direcci√≥n del retorno diario (sube/baja).
- Flujo completo: datos ‚Üí EDA ‚Üí modelos ‚Üí resultados.
- Enfoque con criterio: **no** perseguimos ‚Äúel mejor score‚Äù sin entenderlo.
- Streamlit aporta **orden, demo y reproducibilidad**.
            """
        )

    with colB:
        st.subheader("üöß Limitaciones y futuro")
        st.markdown(
            """
- Overfitting en modelos complejos (especialmente en finanzas).
- No hay datos en tiempo real.
- Falta **validaci√≥n rolling / walk-forward**.
- Pr√≥ximos pasos: regularizaci√≥n, tuning con cuidado, m√°s features, evaluaci√≥n temporal estricta.
            """
        )

    st.success("Fin de la presentaci√≥n.")
    st.button("‚óÄ Anterior", on_click=prev_page)